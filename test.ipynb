{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __init__ import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from segmentation_models_pytorch.encoders import get_encoder\n",
    "from segmentation_models_pytorch.common.blocks import Conv2dReLU\n",
    "from segmentation_models_pytorch.base.model import Model\n",
    "from segmentation_models_pytorch.base import EncoderDecoder\n",
    "# from segmentation_models_pytorch.unet.decoder import UnetDecoder as OrginalUnetDecoder\n",
    "from segmentation_models_pytorch.unet.model import Unet\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scSE_UnetDecoder(Model):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            encoder_channels,\n",
    "            decoder_channels=(256, 128, 64, 32, 16),\n",
    "            final_channels=1,\n",
    "            use_batchnorm=True,\n",
    "            center=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if center:\n",
    "            channels = encoder_channels[0]\n",
    "            self.center = CenterBlock(channels, channels, use_batchnorm=use_batchnorm)\n",
    "        else:\n",
    "            self.center = None\n",
    "\n",
    "        in_channels = self.compute_channels(encoder_channels, decoder_channels)\n",
    "        out_channels = decoder_channels\n",
    "\n",
    "        self.layer1 = scSE_DecoderBlock(in_channels[0], out_channels[0], use_batchnorm=use_batchnorm)\n",
    "        self.layer2 = scSE_DecoderBlock(in_channels[1], out_channels[1], use_batchnorm=use_batchnorm)\n",
    "        self.layer3 = scSE_DecoderBlock(in_channels[2], out_channels[2], use_batchnorm=use_batchnorm)\n",
    "        self.layer4 = scSE_DecoderBlock(in_channels[3], out_channels[3], use_batchnorm=use_batchnorm)\n",
    "        self.layer5 = scSE_DecoderBlock(in_channels[4], out_channels[4], use_batchnorm=use_batchnorm)\n",
    "        self.final_conv = nn.Conv2d(out_channels[4], final_channels, kernel_size=(1, 1))\n",
    "\n",
    "        self.initialize()\n",
    "\n",
    "    def compute_channels(self, encoder_channels, decoder_channels):\n",
    "        channels = [\n",
    "            encoder_channels[0] + encoder_channels[1],\n",
    "            encoder_channels[2] + decoder_channels[0],\n",
    "            encoder_channels[3] + decoder_channels[1],\n",
    "            encoder_channels[4] + decoder_channels[2],\n",
    "            0 + decoder_channels[3],\n",
    "        ]\n",
    "        return channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_head = x[0]\n",
    "        skips = x[1:]\n",
    "\n",
    "        if self.center:\n",
    "            encoder_head = self.center(encoder_head)\n",
    "\n",
    "        x = self.layer1([encoder_head, skips[0]])\n",
    "        x = self.layer2([x, skips[1]])\n",
    "        x = self.layer3([x, skips[2]])\n",
    "        x = self.layer4([x, skips[3]])\n",
    "        x = self.layer5([x, None])\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scSE_hyper_UnetDecoder(Model):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            encoder_channels,\n",
    "            decoder_channels=(256, 128, 64, 32, 16),\n",
    "            final_channels=1,\n",
    "            use_batchnorm=True,\n",
    "            center=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if center:\n",
    "            channels = encoder_channels[0]\n",
    "            self.center = CenterBlock(channels, channels, use_batchnorm=use_batchnorm)\n",
    "        else:\n",
    "            self.center = None\n",
    "\n",
    "        in_channels = self.compute_channels(encoder_channels, decoder_channels)\n",
    "        out_channels = decoder_channels\n",
    "        \n",
    "        self.layer1 = scSE_DecoderBlock(in_channels[0], out_channels[0], use_batchnorm=use_batchnorm)\n",
    "        self.layer2 = scSE_DecoderBlock(in_channels[1], out_channels[1], use_batchnorm=use_batchnorm)\n",
    "        self.layer3 = scSE_DecoderBlock(in_channels[2], out_channels[2], use_batchnorm=use_batchnorm)\n",
    "        self.layer4 = scSE_DecoderBlock(in_channels[3], out_channels[3], use_batchnorm=use_batchnorm)\n",
    "        self.layer5 = scSE_DecoderBlock(in_channels[4], out_channels[4], use_batchnorm=use_batchnorm)\n",
    "        self.final_conv = nn.Conv2d(out_channels[4], final_channels, kernel_size=(1, 1))\n",
    "        \n",
    "        self.logit = nn.Sequential(\n",
    "            nn.Conv2d(384, 64, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(64, 1, kernel_size=1, padding=0),\n",
    "        )\n",
    "\n",
    "        self.initialize()\n",
    "\n",
    "    def compute_channels(self, encoder_channels, decoder_channels):\n",
    "        channels = [\n",
    "            encoder_channels[0] + encoder_channels[1],\n",
    "            encoder_channels[2] + decoder_channels[0],\n",
    "            encoder_channels[3] + decoder_channels[1],\n",
    "            encoder_channels[4] + decoder_channels[2],\n",
    "            0 + decoder_channels[3],\n",
    "        ]\n",
    "        return channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_head = x[0]\n",
    "        skips = x[1:]\n",
    "\n",
    "        if self.center:\n",
    "            encoder_head = self.center(encoder_head)\n",
    "\n",
    "        d5 = self.layer1([encoder_head, skips[0]])\n",
    "        d4 = self.layer2([d5, skips[1]])\n",
    "        d3 = self.layer3([d4, skips[2]])\n",
    "        d2 = self.layer4([d3, skips[3]])\n",
    "        d1 = self.layer5([d2, None])\n",
    "        d1 = self.final_conv(d1)\n",
    "        \n",
    "        print(skips[3].size(1), d1.size(1), d2.size(1), d3.size(1), d4.size(1), d5.size(1))\n",
    "        f = torch.cat((\n",
    "            F.interpolate(skips[3], scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            d1,\n",
    "            F.interpolate(d2, scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            F.interpolate(d3, scale_factor=4, mode='bilinear', align_corners=False),\n",
    "            F.interpolate(d4, scale_factor=8, mode='bilinear', align_corners=False),\n",
    "            F.interpolate(d5, scale_factor=16, mode='bilinear', align_corners=False),\n",
    "        ), 1)\n",
    "        \n",
    "        f = F.dropout2d(f, p=0.50)\n",
    "        f = self.logit(f)\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(EncoderDecoder):\n",
    "    \"\"\"Unet_ is a fully convolution neural network for image semantic segmentation\n",
    "\n",
    "    Args:\n",
    "        encoder_name: name of classification model (without last dense layers) used as feature\n",
    "            extractor to build segmentation model.\n",
    "        encoder_weights: one of ``None`` (random initialization), ``imagenet`` (pre-training on ImageNet).\n",
    "        decoder_channels: list of numbers of ``Conv2D`` layer filters in decoder blocks\n",
    "        decoder_use_batchnorm: if ``True``, ``BatchNormalisation`` layer between ``Conv2D`` and ``Activation`` layers\n",
    "            is used.\n",
    "        classes: a number of classes for output (output shape - ``(batch, classes, h, w)``).\n",
    "        activation: activation function used in ``.predict(x)`` method for inference.\n",
    "            One of [``sigmoid``, ``softmax``, callable, None]\n",
    "        center: if ``True`` add ``Conv2dReLU`` block on encoder head (useful for VGG models)\n",
    "\n",
    "    Returns:\n",
    "        ``torch.nn.Module``: **Unet**\n",
    "\n",
    "    .. _Unet:\n",
    "        https://arxiv.org/pdf/1505.04597\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            encoder_name='resnet34',\n",
    "            encoder_weights='imagenet',\n",
    "            decoder_use_batchnorm=True,\n",
    "            decoder_channels=(256, 128, 64, 32, 16),\n",
    "            scSE=False,\n",
    "            hyper=False,\n",
    "            classes=1,\n",
    "            activation='sigmoid',\n",
    "            center=False,  # usefull for VGG models\n",
    "    ):\n",
    "        encoder = get_encoder(\n",
    "            encoder_name,\n",
    "            encoder_weights=encoder_weights\n",
    "        )\n",
    "        \n",
    "        if scSE == True and hyper==True:\n",
    "            decoder_channels=(64, 64, 64, 64, 64)\n",
    "            classes=64\n",
    "            decoder = scSE_hyper_UnetDecoder(\n",
    "                encoder_channels=encoder.out_shapes,\n",
    "                decoder_channels=decoder_channels,\n",
    "                final_channels=classes,\n",
    "                use_batchnorm=decoder_use_batchnorm,\n",
    "                center=center,\n",
    "            )\n",
    "        elif scSE == True and hyper==False:\n",
    "            decoder = scSE_UnetDecoder(\n",
    "                encoder_channels=encoder.out_shapes,\n",
    "                decoder_channels=decoder_channels,\n",
    "                final_channels=classes,\n",
    "                use_batchnorm=decoder_use_batchnorm,\n",
    "                center=center,\n",
    "            )\n",
    "        else:\n",
    "            decoder = UnetDecoder(\n",
    "                encoder_channels=encoder.out_shapes,\n",
    "                decoder_channels=decoder_channels,\n",
    "                final_channels=classes,\n",
    "                use_batchnorm=decoder_use_batchnorm,\n",
    "                center=center,\n",
    "            )\n",
    "\n",
    "        super().__init__(encoder, decoder, activation)\n",
    "\n",
    "        self.name = 'u-{}'.format(encoder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_encoder('resnet34')(torch.randn(1, 3, 256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unet(scSE=True, hyper=False)(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(1, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBn2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0,\n",
    "                 stride=1, use_batchnorm=True, **batchnorm_parmas):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "                      stride=stride, padding=padding, bias=not (use_batchnorm))\n",
    "        ]\n",
    "        \n",
    "        if use_batchnorm:\n",
    "            layers.append(nn.BatchNorm2d(out_channels, **batchnorm_parmas))\n",
    "            \n",
    "        self.block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "\n",
    "class sSE(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = ConvBn2d(in_channels=out_channels, out_channels=1, kernel_size=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class cSE(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features=out_channels, out_features=int(out_channels / 2), bias=False)\n",
    "        self.linear2 = nn.Linear(in_features=int(out_channels / 2), out_features=out_channels, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = nn.AdaptiveAvgPool2d(1)(x).view(b, c)\n",
    "        y = self.linear1(y)\n",
    "        y = torch.relu(y)\n",
    "        y = self.linear2(y)\n",
    "        y = torch.sigmoid(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scSE_DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_batchnorm=True):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            Conv2dReLU(in_channels, out_channels, kernel_size=3, padding=1, use_batchnorm=use_batchnorm),\n",
    "            Conv2dReLU(out_channels, out_channels, kernel_size=3, padding=1, use_batchnorm=use_batchnorm),\n",
    "        )\n",
    "        self.spatial_gate = sSE(out_channels)\n",
    "        self.channel_gate = cSE(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip = x\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        if skip is not None:\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "        x = self.block(x)\n",
    "        g1 = self.spatial_gate(x)\n",
    "        g2 = self.channel_gate(x)\n",
    "        x = g1 * x + g2 * x\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scSE_UnetDecoder(Model):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            encoder_channels,\n",
    "            decoder_channels=(256, 128, 64, 32, 16),\n",
    "            final_channels=1,\n",
    "            use_batchnorm=True,\n",
    "            center=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if center:\n",
    "            channels = encoder_channels[0]\n",
    "            self.center = CenterBlock(channels, channels, use_batchnorm=use_batchnorm)\n",
    "        else:\n",
    "            self.center = None\n",
    "\n",
    "        in_channels = self.compute_channels(encoder_channels, decoder_channels)\n",
    "        out_channels = decoder_channels\n",
    "\n",
    "        self.layer1 = scSE_DecoderBlock(in_channels[0], out_channels[0], use_batchnorm=use_batchnorm)\n",
    "        self.layer2 = scSE_DecoderBlock(in_channels[1], out_channels[1], use_batchnorm=use_batchnorm)\n",
    "        self.layer3 = scSE_DecoderBlock(in_channels[2], out_channels[2], use_batchnorm=use_batchnorm)\n",
    "        self.layer4 = scSE_DecoderBlock(in_channels[3], out_channels[3], use_batchnorm=use_batchnorm)\n",
    "        self.layer5 = scSE_DecoderBlock(in_channels[4], out_channels[4], use_batchnorm=use_batchnorm)\n",
    "        self.final_conv = nn.Conv2d(out_channels[4], final_channels, kernel_size=(1, 1))\n",
    "\n",
    "        self.initialize()\n",
    "\n",
    "    def compute_channels(self, encoder_channels, decoder_channels):\n",
    "        channels = [\n",
    "            encoder_channels[0] + encoder_channels[1],\n",
    "            encoder_channels[2] + decoder_channels[0],\n",
    "            encoder_channels[3] + decoder_channels[1],\n",
    "            encoder_channels[4] + decoder_channels[2],\n",
    "            0 + decoder_channels[3],\n",
    "        ]\n",
    "        return channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_head = x[0]\n",
    "        skips = x[1:]\n",
    "\n",
    "        if self.center:\n",
    "            encoder_head = self.center(encoder_head)\n",
    "\n",
    "        x = self.layer1([encoder_head, skips[0]])\n",
    "        x = self.layer2([x, skips[1]])\n",
    "        x = self.layer3([x, skips[2]])\n",
    "        x = self.layer4([x, skips[3]])\n",
    "        x = self.layer5([x, None])\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, c, _, _ = img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nn.AdaptiveAvgPool2d(1)(img).view(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from segmentation_models_pytorch.unet.model import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  8.3107,  18.5793,  20.5211,  ...,  12.2965,  13.5621,   5.7937],\n",
       "          [ 15.2626,  25.5527,  25.5018,  ...,  15.2186,  16.8413,  10.5566],\n",
       "          [ 13.7626,  23.1354,  23.1595,  ...,  17.2275,  17.8399,  11.1414],\n",
       "          ...,\n",
       "          [-11.3372, -17.1666, -16.2905,  ...,  11.1589,  11.1022,   4.9724],\n",
       "          [ -9.5579, -16.2302, -15.7735,  ...,  14.1393,  14.7918,   7.0590],\n",
       "          [-13.6933, -16.8718, -15.7791,  ...,  15.3918,  14.4391,  12.7882]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unet(\"resnet152\", encoder_weights=\"imagenet\", scSE=True, hyper=True)(torch.randn(1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
